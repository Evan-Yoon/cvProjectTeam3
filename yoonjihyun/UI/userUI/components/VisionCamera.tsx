import React, { useRef, useState, useEffect } from "react";
import Webcam from "react-webcam";
import { Geolocation } from "@capacitor/geolocation";
import { sendHazardReport } from "../src/api/report";
import NpuTflite from "../NpuTfliteBridge";
import { YoloParser, DetectedBox } from "../src/utils/YoloParser";

const VisionCamera: React.FC = () => {
  const webcamRef = useRef<Webcam>(null);
  const [status, setStatus] = useState<string>("ëª¨ë¸ ë¡œë”© ì¤‘...");
  const [inferenceInfo, setInferenceInfo] = useState<string>(""); // ë””ë²„ê¹…ìš© ì¶”ë¡  ì •ë³´
  const isMounted = useRef(true);
  const [modelLoaded, setModelLoaded] = useState(false);

  // 1. ëª¨ë¸ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
  useEffect(() => {
    const loadModel = async () => {
      try {
        console.log("ğŸ› ï¸ YOLO11 ëª¨ë¸ ë¡œë“œ ì‹œë„...");
        // public/wasm/yolo11n_float32.tflite ê²½ë¡œ ì‚¬ìš©
        const result = await NpuTflite.loadModel({ modelPath: "wasm/yolo11n_float32.tflite" });
        console.log("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ:", result);
        setStatus("ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ");
        setModelLoaded(true);
      } catch (error) {
        console.error("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", error);
        setStatus("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨");
      }
    };
    loadModel();
  }, []);

  // 2. í†µí•© ë£¨í”„: 3ì´ˆë§ˆë‹¤ ì´¬ì˜ -> ì¶”ë¡  -> ì „ì†¡
  useEffect(() => {
    if (!modelLoaded) return;

    isMounted.current = true;
    const loopInterval = setInterval(async () => {
      if (!isMounted.current || !webcamRef.current) return;

      const imageSrc = webcamRef.current.getScreenshot();
      if (!imageSrc) return;

      try {
        // [1] ì´ë¯¸ì§€ ìº¡ì²˜ (Base64 í—¤ë” ì œê±°)
        const base64Data = imageSrc.split(",")[1];

        // [2] NPU ì¶”ë¡  ì‹¤í–‰
        const startTime = performance.now();
        const result = await NpuTflite.detect({ image: base64Data });
        const endTime = performance.now();
        const duration = (endTime - startTime).toFixed(0);

        // ê²°ê³¼ íŒŒì‹± ë° ê·¸ë¦¬ê¸°
        let infoMsg = `ì‹œê°„: ${duration}ms`;
        let finalImageBase64 = base64Data;

        if (result && result.data && result.data.length > 0) {
          infoMsg += ` | ë°ì´í„°: ${result.data.length}ê°œ`;

          // íŒŒì„œ í˜¸ì¶œ
          const boxes = YoloParser.parse(result.data, result.shape || []);

          if (boxes.length > 0) {
            infoMsg += ` | ğŸ“¦ê°ì²´: ${boxes.length}ê°œ`;

            // [Canvas Drawing Logic]
            const img = new Image();
            img.src = imageSrc;
            await new Promise((resolve) => { img.onload = resolve; });

            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d');

            if (ctx) {
              ctx.drawImage(img, 0, 0);

              ctx.lineWidth = 3;
              ctx.font = "bold 24px Arial";

              boxes.forEach((box) => {
                const x = box.x * canvas.width;
                const y = box.y * canvas.height;
                const w = box.w * canvas.width;
                const h = box.h * canvas.height;

                const left = x - w / 2;
                const top = y - h / 2;

                ctx.strokeStyle = "#00FF00";
                ctx.strokeRect(left, top, w, h);

                const label = `${box.className} ${(box.score * 100).toFixed(0)}%`;
                const textWidth = ctx.measureText(label).width;

                ctx.fillStyle = "#00FF00";
                ctx.fillRect(left, top - 30, textWidth + 10, 30);

                ctx.fillStyle = "black";
                ctx.fillText(label, left + 5, top - 6);
              });

              finalImageBase64 = canvas.toDataURL("image/jpeg", 0.8).split(",")[1];
            }
          } else {
            infoMsg += " | âšªê°ì²´ì—†ìŒ";
          }
        }
        setInferenceInfo(infoMsg);
        console.log(`ğŸ” ì¶”ë¡  ì™„ë£Œ: ${infoMsg}`);

        // [3] ë¦¬í¬íŠ¸ ì „ì†¡
        const position = await Geolocation.getCurrentPosition();

        console.log("ğŸ“¤ 3ì´ˆ ì£¼ê¸° ë°ì´í„° ì „ì†¡ ì¤‘...");
        await sendHazardReport({
          latitude: position.coords.latitude,
          longitude: position.coords.longitude,
          hazard_type: "Periodic_Monitor",
          risk_level: 1,
          description: `ëª¨ë‹ˆí„°ë§ (3ì´ˆ ì£¼ê¸°) ${new Date().toLocaleTimeString()} / ${infoMsg}`,
          imageBase64: finalImageBase64
        });

        setStatus("ì „ì†¡ ì™„ë£Œ");
        setTimeout(() => setStatus("ëª¨ë‹ˆí„°ë§ ì¤‘..."), 1000);

      } catch (error) {
        console.error("ë£¨í”„ ì—ëŸ¬:", error);
        setStatus("ì—ëŸ¬ ë°œìƒ");
        setInferenceInfo(`ì—ëŸ¬: ${error}`);
      }
    }, 3000); // 3ì´ˆ ì£¼ê¸°

    return () => {
      isMounted.current = false;
      clearInterval(loopInterval);
    };
  }, [modelLoaded]);

  return (
    <div className="relative w-full h-full bg-black flex justify-center items-center overflow-hidden">
      <Webcam
        ref={webcamRef}
        audio={false}
        screenshotFormat="image/jpeg"
        videoConstraints={{ facingMode: "environment" }}
        style={{
          position: "absolute",
          width: "100%",
          height: "100%",
          objectFit: "cover",
        }}
      />

      {/* ìƒíƒœ í‘œì‹œ */}
      <div className="absolute top-4 right-4 flex flex-col items-end gap-2 z-50">
        <div className="bg-black/60 px-3 py-1 rounded-full">
          <p className="text-yellow-400 font-mono text-xs font-bold animate-pulse">
            {status}
          </p>
        </div>
        {inferenceInfo && (
          <div className="bg-blue-900/80 px-3 py-1 rounded-lg border border-blue-400">
            <p className="text-white font-mono text-[10px] whitespace-pre-wrap max-w-[200px]">
              {inferenceInfo}
            </p>
          </div>
        )}
      </div>
    </div>
  );
};

export default VisionCamera;