# GenSpark AI 프롬프트 템플릿: 'WalkMate' 프로젝트 포트폴리오 PPT 기획안 생성

**[프롬프트 시작 부분 - GenSpark AI에 그대로 복사해서 붙여넣으세요]**

너는 지금부터 IT 포트폴리오 및 피칭 마스터이자 전문 PPT 기획자야.
아래 제공된 내(팀장 및 프론트엔드/UI 담당 '윤지현') 프로젝트 데이터를 바탕으로, 내일 모레 있을 중요한 취업용 포트폴리오 겸 최종 프로젝트 발표용 PPT 슬라이드 대본과 시각화 기획안을 작성해 줘.
각 슬라이드별로 어떤 텍스트가 들어가야 하는지, 어떤 이미지나 도표(아이콘 포함)가 들어가야 하는지 구체적으로 지시해 주고, 청중을 설득할 수 있도록 스토리텔링(5W1H) 기법을 활용해 줘. 특히 '나(윤지현)'의 성과와 고민, 실패를 극복한 과정이 돋보이도록 구성해 줘.

---

## 📌 [기본 제공 데이터: 프로젝트 'WalkMate' 핵심 정보]

### [Slide 1: 표지]
- **프로젝트명**: WalkMate (Tmap API와 온디바이스 AI를 결합한 시각장애인 보행 보조 및 도시 환경 개선 솔루션)
- **발표자**: 윤지현 (팀장 / 프론트엔드 및 클라이언트 UI/UX 총괄 개발)
- **슬라이드 지시사항**: 시각장애인의 안전한 보행을 상징하는 직관적이고 따뜻한 느낌의 커버 디자인 및 부제 제안.

### [Slide 2: 목차]
01. 프로젝트 개요 (Overview)
02. 프로젝트 팀 구성 및 역할 (Team Roles)
03. 프로젝트 수행 절차 및 방법 (Methodology)
04. 프로젝트 수행 경과 (Results & Trouble Shooting)
05. 자체 평가 의견 (Self-Evaluation)

### [Slide 3~4: 01. 프로젝트 개요]
- **기획 의도 및 배경 (5W1H 적용)**:
  - **Who**: 시각장애인 및 휠체어 등 보행 약자.
  - **Why (데이터 소스)**: 보행 약자의 70% 이상이 인도 위 무단 방치된 전동 킥보드, 공유 자전거, 볼라드 등으로 인해 심각한 부상 위험에 노출되고 있음 (교통안전공단 보행자 사고 통계 등 가상 데이터 인용 요망). 기존 흰 지팡이는 발밑만 커버하며, 점자블록은 파손/단절 구역이 무려 40%에 달함.
  - **What**: 카메라가 전방 장애물을 인식해 음성으로 경고하고, 점자블록 단절 구간에서도 Tmap 보행자 내비게이션으로 목적지까지 непрерывный(중단 없는) 가이드 제공.
  - **Where/When/How**: 언제 어디서나 스마트폰을 가슴(체스트 하네스)에 매달면, 오프라인 환경(온디바이스 AI)에서도 실시간 0.3초 내로 사물을 인식해 양방향 음성 인티페이스(STT/TTS)로 사용자에게 길을 안내.
- **차별성**: 서버 통신 지연이 없는 온디바이스 AI(YOLOv26n) 처리. 일반 네비게이션이 무시하는 10m 이내 초단거리 미세 장애물 회피 가이드(시계 방향 안내 적용).
- **프로젝트 구조**: Client(Web-App 하이브리드) ↔ FastAPI Backend ↔ AWS S3 / Supabase ↔ Admin Dashboard.
- **활용 장비/재료 (Tech Stack)**: (이후 도구 리스트에서 상세 서술)
- **기대 효과 (BM 및 비즈니스 실무 활용성)**: 
  - 보행 약자의 안전망 구축(사회적 가치).
  - 지자체 및 PM(퍼스널 모빌리티) 업체에 '실시간 무단 방치 위험물 위치/사진/히트맵 데이터'를 B2G/B2B로 제공(판매)하여 견인 비용 절감 및 도로 유지보수 자동화.

### [Slide 5: 02. 프로젝트 팀 구성 및 역할]
- **멘토 지원 내역**: 전체 아키텍처 피드백, 모델 경량화 방향성 제시, 코드 리뷰.
- **윤지현 (본인 / 팀장 / 프론트엔드 UI/UX)**: 
  - 기획 총괄 및 User/Admin 화면 UI/UX 설계.
  - Capacitor, React, Vite를 이용한 크로스 플랫폼(Android/iOS) 하이브리드 앱 구축.
  - Tmap API 실시간 턴바이턴 보행 가이드 로직 구현.
  - Capacitor 네이티브 플러그인을 활용한 디바이스 센서 제어(GPS, 나침반 센서 퓨전), 화면 터치 없는 100% STT/TTS 음성 주도형 인터페이스 개발.
- **이지호 (백엔드 및 파이프라인)**: FastAPI 아키텍처 설계, Supabase 및 AWS S3 연동 데이터 파이프라인 구축.
- **최현석 (AI 및 알고리즘)**: YOLOv26n(TFLite) 학습 및 경량화, 객체 종류별 3단계 우선순위 알고리즘 개발.

### [Slide 6: 03. 프로젝트 수행 절차 및 방법]
(타임라인/도식화 형태로 시각화 요망)
- **1단계 (02.09 ~ 02.10) - 기획 및 페르소나 설계**: 시각장애인 행동 패턴 분석 및 '음성 최우선' UI 기획.
- **2단계 (02.11 ~ 02.12) - 코어 아키텍처 및 데이터 준비**: React 기반 User/Admin 레이아웃 세팅, 킥보드/볼라드 커스텀 이미지 데이터셋 확보 및 학습.
- **3단계 (02.13 ~ 진행) - 전략적 Pivot 및 융합 개발**: 기존 단순 점자블록 인식의 한계를 깨닫고, **"점자블록이 없어도 길을 잃지 않는 Tmap 연동"**으로 노선 변경. 프론트엔드 단에서 AI 추론 스레드와 길안내 스레드 병렬 결합.
- **4단계 (현재) - T/S 및 현장 최적화**: 체스트 마운트 착용 시 나침반 센서 오차 디버깅, 프레임 드랍 최적화.

### [Slide 7~9: 04. 프로젝트 수행 경과 (주요 성과 및 핵심 로직 시연)]
#### 툴킷 (아이콘 포함 기획 요망): 
- 🎨 **Frontend**: `React(⚛️)`, `TypeScript(📘)`, `Tailwind CSS(🌊)`, `Vite(⚡)`, `Recharts(📊)`, `Leaflet(🗺️)`
- 📱 **Mobile/Native**: `Capacitor(🔋)` (Geolocation, Motion, TTS, STT 플러그인 연동)
- 🧠 **AI**: `YOLOv26n (TFLite CPU/NPU 온디바이스 추론)`
- ⚙️ **Backend/Cloud**: `FastAPI(🚀)`, `Supabase(🟩)`, `AWS S3(☁️)`
#### 핵심 기능(결과) 상세 (나의 UI 기여도 중심):
1. **극강의 접근성 (100% Voice UI)**: 화면 터치 없이 "~~로 안내해 줘" 말하면 STT로 인식하여 Tmap 목적지 확인 및 TTS 음성 가이드 큐 시스템 구현. (시연 이미지/영상 자리 확보)
2. **복합 S/W 센서 퓨전 (Sensor Fusion)**: 체스트 마운트로 걸을 때 나침반이 심하게 튀는 현상을 잡기 위해, 1.5m 이상 이동 시 GPS 궤적(Bearing)을 나침반 방향과 결합하고 Low-Pass Filter(알파=0.15)를 적용하여 흔들리지 않는 방향성 제공.
3. **지능형 이탈 방지 (Clock-Face Warning)**: 단순히 경로 이탈을 알리는 것이 아니라, 시각장애인이 이해하기 쉽게 "경로 이탈, 3시 방향으로 돌아주세요" 와 같이 상대 각도를 실시간 계산해 정정 멘트 출력.
4. **위험물 객체 거리 기반 필터링**: YOLOv26n이 던져주는 Bounding Box 크기를 핀홀 카메라 공식으로 역산해 거리를 추정. 위험도 High(자전거 등)는 5m 이내 즉시 알림, Medium(의자 등)은 3m 이내 알림으로 '알림 피로도 최소화'.
5. **실시간 관제 대시보드 (Admin)**: 시각장애인의 앱에서 전송된 위험물 사진/좌표를 관리자가 실시간으로 지도(Heatmap)와 통계(Recharts)로 모니터링하고 처리(Action)하는 대시보드 구축 완료.

### [Slide 10~11: Trouble Shooting (실패 및 성능 한계 사례 - ★핵심 강조★)]
- ❌ **실패 사례 1 (단순 자이로스코프 의존의 맹점)**:
  - **문제**: 스마트폰을 손에 들지 않고 가슴(체스트 하네스)에 메달고 걸었더니, 상하좌우 바운스가 심해 앱 내 나침반 화살표가 360도로 미친 듯이 회전함. (길안내 완전 실패)
  - **극복(Pivot)**: 사용자가 서 있을 때는 나침반+LPF(저역통과필터)를 적용하고, **걸어가기 시작하면 무조건 GPS 이동 궤적(Trajectory)**의 방향을 신뢰하도록 가중치를 90% 확 끌고 오는 **'센서 퓨전(Sensor Fusion)' 알고리즘**을 독자적으로 짜서 넣음. 결과적으로 심한 흔들림에도 앞을 정확히 가리키는 데 성공.
- 📉 **낮은 성능 데이터 사례 (STT 노이즈 및 STT-TTS 충돌)**:
  - **문제**: 야외 테스트 중, 바람 소리나 자동차 클락션이 울리면 내장 STT(음성 인식)가 "종료" 명령을 오인식하거나 완전히 먹통이 됨. 게다가 Tmap 길안내 멘트 재생 중에 전방 자전거(위험)가 나타나면 두 TTS 멘트가 겹쳐 알아들을 수 없는 오디오 충돌 발생.
  - **개선안 / 배운점**: STT는 야외 소음 환경에서 근본적 한계가 있음을 통감함. 추후 VAD(Voice Activity Detection) 노이즈 캔슬레이션 층을 도입해야 함. TTS 충돌 문제는, 현재 멘트 진행 상태를 체크하는 큐(Queue) 시스템을 짜임새 있게 작성하여, **위험물 알림을 무조건 최우선**으로 빼고 기존 네비게이션 멘트를 지연(지연 재생)시키는 논리로 H/W적 한계를 S/W 아키텍처로 극복해 냄.

### [Slide 12: 05. 자체 평가 의견]
- **완성도 자체 평가 (8.5점 / 10점)**
  - Tmap과 온디바이스 AI 비전을 하이브리드 앱 하나로 매끄럽게 연결했다는 점에서 높은 점수를 줌. 특히 실질적인 타겟(시각장애인)의 Pain Point를 고려한 시계 방향 음성 인터페이스 구성은 실용성이 매우 뛰어남.
  - 다만 GPS 자체의 오차(도심 빌딩숲 반사파 등) 1~3m 물리적 한계를 온전히 소프트웨어로만 제어하기란 불가능했기에 1.5점 감점.
- **아쉬운 점**: 야외에서의 STT 오인식 문제와 시각장애인의 보폭에 완벽히 맞춘 턴바이턴 딜레이 미세조정이 아직 현장 테스트 데이터 부족으로 최적화되지 않음.
- **성장 및 향후 경력 계획 (프론트엔드 리드로서의 역량)**:
  - 단순 화면 마크업(React)을 넘어, 하드웨어 센서(GPS, 나침반, 오디오, 카메라)와 직접 통신(Capacitor)하며 운영체제 단의 라이프사이클을 깊게 제어하는 역량을 길렀음. 
  - 문제가 생겼을 때 H/W 탓을 하기보다 '센서 퓨전'처럼 S/W적으로 뚫고 나가는 **문제 해결력 강한 프론트엔드 개발자**로 성장했음을 확신함.

---
**[프롬프트 끝]**

위 내용을 바탕으로 발표 시간 약 10분 내외 분량의 전문적인 포트폴리오 슬라이드 덱 스크립트(발표자 스크립트 포함)를 완벽하게 짜줘. 각 장마다 슬라이드에 띄울 키워드와, 내가 입으로 말할 대본(Script)을 명확히 구분해 줘.
