# 포트폴리오용 AI 프롬프트 해결 사례: 아키텍처 불일치 문제

이 문서는 프로젝트 수행 중 발생한 **카메라 및 NPU 객체 인식 모듈 도입 실패 사례**와, 이를 프롬프트 수정을 통해 어떻게 단계적으로 해결했는지 정리한 포트폴리오용 자료입니다.

## 📌 주제: 하이브리드 앱(React + Capacitor) 환경에서의 하드웨어 제어 구조 설계 실패와 해결

---

### Phase 1: 초기 접근 및 첫 번째 실패
**목표:** 앱 내에서 카메라를 켜고 실시간으로 객체 인식을 수행하는 기능(`VisionCamera`) 구현

**🔴 초기 프롬프트 (Failure 1)**
> *"리액트 앱에서 카메라를 켜고 실시간으로 사물을 탐지해서 화면에 박스를 쳐주는 카메라 컴포넌트를 만들어줘."*

* **AI의 답변 및 조치:** AI는 가장 대중적인 모바일 카메라 라이브러리인 `react-native-vision-camera` 모듈을 추천하고 관련 코드를 작성해 주었습니다.
* **실패 결과:** 모듈 설치 후 구동 시 `useCameraPermission is not exported by react-native-web` (권한 관련 모듈을 찾을 수 없음) 빌드 에러가 발생했습니다.
* **실패 원인:** AI는 "리액트 앱"이라는 단어만 보고 모바일 개발의 표준인 **React Native 환경으로 착각**했습니다. 현재 프로젝트는 Vite 기반의 웹 애플리케이션을 Capacitor로 감싼 하이브리드 형태인데, 순수 Native 하드웨어 모듈을 웹 환경에 강제로 적용하려다 발생한 **아키텍처 불일치(Architecture Mismatch)** 문제였습니다.

---

### Phase 2: 에러 로그에 의존한 단편적 디버깅의 한계
원인을 파악하지 못한 채 에러 로그 자체만 AI에게 물어보는 실수를 범했습니다.

**🔴 1차 수정 프롬프트 (Failure 2)**
> *"react-native-vision-camera를 설치했는데 `useCameraPermission is not exported by react-native-web` 에러가 나. 프로젝트는 Capacitor를 쓰고 있어. 이 에러 어떻게 해결해?"*

* **AI의 답변 및 조치:** AI는 `react-native-web` 패키지를 추가 설치하여 웹 호환성을 강제 맵핑시키고, Capacitor 동기화(`npx cap sync`)를 다시 진행하라는 가이드와 땜질식 회피 코드를 제시했습니다.
* **실패 결과:** 설정 후 에러는 넘어간 듯 보였으나, 실제 객체 인식 후 화면에 박스를 그려주는 변수를 인식하지 못하는 `Cannot find name 'boxes'` 에러가 연쇄적으로 발생하거나, 모바일 빌드 시 치명적인 호환성 크래시가 났습니다.
* **실패 원인:** **본질적인 문제를 무시하고 현상(에러 메시지)만 프롬프트에 넣어 생긴 결과**입니다. `react-native-web`은 UI 컴포넌트(View, Text)만 웹용으로 변환해 줄 뿐, 카메라나 NPU 리소스 같은 네이티브 디바이스 권한 제어를 웹 브라우저 환경으로 돌리지 못하기 때문에 정상 동작할 수 없었습니다.

---

### Phase 3: 환경의 명확한 정의와 구조적 해결 (성공)
문제가 코드의 문법이 아닌 **'실행 환경과 기술 스택의 불일치'**에 있음을 깨닫고, 시스템 아키텍처를 AI에게 정확히 인지시키는 방향으로 프롬프트를 전면 수정했습니다.

**🟢 최종 수정 프롬프트 (Resolution)**
> *"내 프로젝트는 React Native가 아니라 **React 기반의 순수 웹 앱(Vite)이고, 이를 Capacitor로 감싸운 구조**야. 따라서 네이티브 전용 모듈은 빌드 에러가 나. 
> 이 환경에서 네이티브 의존성 없이 **1) 웹캠을 띄우고**, **2) 실시간 프레임을 캡처해서 웹 호환(WASM/TFLite) 모듈로 넘겨**, **3) 객체 인식(YOLO)을 수행**하려면 어떤 라이브러리를 써야 하고 전체적인 아키텍처를 어떻게 짜야 할까?"*

* **AI의 답변 및 조치:**
  1. 네이티브 의존성을 완전히 배제한 순수 웹 표준 라이브러리인 **`react-webcam`**을 사용할 것을 제안.
  2. Canvas를 이용해 `react-webcam`의 프레임을 640x640 보정(Letterboxing)하여 캡처.
  3. 캡처된 이미지를 프로젝트 자체 하드웨어 가속 모듈(`NpuTflite`)로 포워딩하여 추론 후 그 결과를 화면에 렌더링하도록 코드를 재설계해 줌.
* **최종 성과:** `react-native-vision-camera`를 모두 걷어내고 코드를 재작성한 결과, 네이티브 빌드 에러가 완전히 사라졌습니다. 또한 브라우저 스레드 안에서 프레임 확보 및 TFLite 추론 사이클을 완벽하게 동기화하여 실시간 객체 인식 컴포넌트(`VisionCamera.tsx`) 구현에 성공했습니다.

---

## 💡 포트폴리오 면접(어필) 포인트
1. **AI 활용의 함정 인지 지능:** AI는 제한된 정보가 주어지면 가장 '대중적인 스택'을 임의로 가정합니다. 개발자가 자신의 프로젝트 아키텍처(하이브리드 앱 vs 네이티브 앱)를 명확히 이해하고 통제하지 않으면 AI가 프로젝트를 망가뜨릴 수 있다는 점을 배웠습니다.
2. **단편적 해결에서 근본적 해결로의 발전:** 에러 코드 자체(`useCameraPermission 에러 해결해줘`)를 검색해 땜질 처방하던 습관에서 벗어나, 기술 스택 간의 근본적인 호환성을 분석하고 이를 바탕으로 설계 방향 자체를 변경(React Native 모듈 폐기 → Web 표준 API 활용)하는 **문제 해결력과 결단력**을 보여줍니다.
3. **프롬프트 엔지니어링 역량:** 코딩을 위한 프롬프트 작성 시, 단순한 '기능 요구사항' 외에도 **환경(Environment)**, **제약조건(Constraints)**, **설계 구조(Architecture)**를 명확히 선언해야 단번에 원하는 결과를 얻을 수 있다는 실전 노하우를 습득했습니다.
